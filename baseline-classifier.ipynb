{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !gdown https://drive.google.com/uc?id=11AENyWl6fD5rgoIIwnZy692vE_pqZQ8Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown https://drive.google.com/uc?id=1ZCgMnlPTQvmU4KB5HQpLGFNZt-uEzNks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip zipfile.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm zipfile.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas razdel tqdm python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "I1214 03:00:55.546691 139737074411328 file_utils.py:39] PyTorch version 1.3.1 available.\n",
      "I1214 03:00:56.244422 139737074411328 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from main import QADataset\n",
    "from razdel import tokenize\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from preprocess_dataset import tokenize_text\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertModel, BertTokenizer, BertForMaskedLM, BertConfig\n",
    "from get_bert_embeddings import get_embeddings, embed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>char_answer_span</th>\n",
       "      <th>paragraph_tokens</th>\n",
       "      <th>word_answer_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14754</td>\n",
       "      <td>60544</td>\n",
       "      <td>Первые упоминания о строении человеческого тел...</td>\n",
       "      <td>Где встречаются первые упоминания о строении ч...</td>\n",
       "      <td>в Древнем Египте</td>\n",
       "      <td>(60, 76)</td>\n",
       "      <td>Первые упоминания о строении человеческого тел...</td>\n",
       "      <td>7,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13859</td>\n",
       "      <td>1604</td>\n",
       "      <td>Телескоп имеет модульную структуру и содержит ...</td>\n",
       "      <td>Как называется корректирующая оптическая систе...</td>\n",
       "      <td>COSTAR</td>\n",
       "      <td>(187, 193)</td>\n",
       "      <td>Телескоп имеет модульную структуру и содержит ...</td>\n",
       "      <td>28,29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8310</td>\n",
       "      <td>30350</td>\n",
       "      <td>Критики теории Вегенера поставили во главу угл...</td>\n",
       "      <td>Какая теория была отвергнута после смерти Веге...</td>\n",
       "      <td>теория дрейфа материков</td>\n",
       "      <td>(335, 358)</td>\n",
       "      <td>Критики теории Вегенера поставили во главу угл...</td>\n",
       "      <td>51,54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8766</td>\n",
       "      <td>53270</td>\n",
       "      <td>При нагревании кусочки янтаря становятся очень...</td>\n",
       "      <td>Чему не уступают по красоте изделия из прессов...</td>\n",
       "      <td>изделиям из монолитных камней</td>\n",
       "      <td>(852, 881)</td>\n",
       "      <td>При нагревании кусочки янтаря становятся очень...</td>\n",
       "      <td>128,132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14719</td>\n",
       "      <td>75698</td>\n",
       "      <td>Нисходящие дифтонги со слабым гласным /i/ и /u...</td>\n",
       "      <td>На какие группы классифицируют дифтонги?</td>\n",
       "      <td>оральные и назальные</td>\n",
       "      <td>(735, 755)</td>\n",
       "      <td>Нисходящие дифтонги со слабым гласным / i / и ...</td>\n",
       "      <td>141,144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0         14754        60544   \n",
       "1         13859         1604   \n",
       "2          8310        30350   \n",
       "3          8766        53270   \n",
       "4         14719        75698   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Первые упоминания о строении человеческого тел...   \n",
       "1  Телескоп имеет модульную структуру и содержит ...   \n",
       "2  Критики теории Вегенера поставили во главу угл...   \n",
       "3  При нагревании кусочки янтаря становятся очень...   \n",
       "4  Нисходящие дифтонги со слабым гласным /i/ и /u...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Где встречаются первые упоминания о строении ч...   \n",
       "1  Как называется корректирующая оптическая систе...   \n",
       "2  Какая теория была отвергнута после смерти Веге...   \n",
       "3  Чему не уступают по красоте изделия из прессов...   \n",
       "4           На какие группы классифицируют дифтонги?   \n",
       "\n",
       "                          answer char_answer_span  \\\n",
       "0               в Древнем Египте         (60, 76)   \n",
       "1                         COSTAR       (187, 193)   \n",
       "2        теория дрейфа материков       (335, 358)   \n",
       "3  изделиям из монолитных камней       (852, 881)   \n",
       "4           оральные и назальные       (735, 755)   \n",
       "\n",
       "                                    paragraph_tokens word_answer_span  \n",
       "0  Первые упоминания о строении человеческого тел...             7,10  \n",
       "1  Телескоп имеет модульную структуру и содержит ...            28,29  \n",
       "2  Критики теории Вегенера поставили во главу угл...            51,54  \n",
       "3  При нагревании кусочки янтаря становятся очень...          128,132  \n",
       "4  Нисходящие дифтонги со слабым гласным / i / и ...          141,144  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sberquad.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_tokens = [i.split() for i in data.paragraph_tokens]\n",
    "que_tokens = [tokenize_text(i) for i in data.question]\n",
    "answer_spans = data.word_answer_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index={\"[PAD]\":0, \"[CLS]\":1, \"[SEP]\":2}\n",
    "\n",
    "for sent in par_tokens:\n",
    "    for token in sent:\n",
    "        if token not in word2index:\n",
    "            word2index[token] = len(word2index)\n",
    "\n",
    "for que in que_tokens:\n",
    "    for token in que:\n",
    "        if token not in word2index:\n",
    "            word2index[token] = len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1214 03:01:02.926850 139737074411328 tokenization.py:187] loading vocabulary file lm/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"lm\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are good to go!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('Bummer!  Training on CPU ...')\n",
    "else:\n",
    "    print('You are good to go!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = embed_data(dataset.x_data)\n",
    "# тут все ок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем датасет на трейн/тест (80%, 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40267"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>char_answer_span</th>\n",
       "      <th>paragraph_tokens</th>\n",
       "      <th>word_answer_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9363</td>\n",
       "      <td>30299</td>\n",
       "      <td>Бале́т (фр. ballet, от итал. ballare — танцева...</td>\n",
       "      <td>Когда появился бессюжетный балет?</td>\n",
       "      <td>в XX веке</td>\n",
       "      <td>(267, 276)</td>\n",
       "      <td>Бале́т ( фр . ballet , от итал . ballare — тан...</td>\n",
       "      <td>41,44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14985</td>\n",
       "      <td>15892</td>\n",
       "      <td>Стоявшие во главе города подеста с конца XII в...</td>\n",
       "      <td>Кем был захвачен Франческо I Каррара?</td>\n",
       "      <td>миланцами</td>\n",
       "      <td>(510, 519)</td>\n",
       "      <td>Стоявшие во главе города подеста с конца XII в...</td>\n",
       "      <td>89,90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10642</td>\n",
       "      <td>74181</td>\n",
       "      <td>В 1951 году американский изобретатель и предпр...</td>\n",
       "      <td>Кто такой Лео Фендер?</td>\n",
       "      <td>американский изобретатель и предприниматель</td>\n",
       "      <td>(12, 55)</td>\n",
       "      <td>В 1951 году американский изобретатель и предпр...</td>\n",
       "      <td>3,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11879</td>\n",
       "      <td>33131</td>\n",
       "      <td>Исследованиями балтийских языков и их связей с...</td>\n",
       "      <td>Какой словарь составил Р. Траутман?</td>\n",
       "      <td>Балто-славянский словарь</td>\n",
       "      <td>(120, 144)</td>\n",
       "      <td>Исследованиями балтийских языков и их связей с...</td>\n",
       "      <td>17,19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14494</td>\n",
       "      <td>27900</td>\n",
       "      <td>Подвеска смягчает и поглощает удары и толчки, ...</td>\n",
       "      <td>Какая подвеска применяется на современных трол...</td>\n",
       "      <td>с пневматическими упругими элементами</td>\n",
       "      <td>(200, 237)</td>\n",
       "      <td>Подвеска смягчает и поглощает удары и толчки ,...</td>\n",
       "      <td>28,32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0          9363        30299   \n",
       "1         14985        15892   \n",
       "2         10642        74181   \n",
       "3         11879        33131   \n",
       "4         14494        27900   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Бале́т (фр. ballet, от итал. ballare — танцева...   \n",
       "1  Стоявшие во главе города подеста с конца XII в...   \n",
       "2  В 1951 году американский изобретатель и предпр...   \n",
       "3  Исследованиями балтийских языков и их связей с...   \n",
       "4  Подвеска смягчает и поглощает удары и толчки, ...   \n",
       "\n",
       "                                            question  \\\n",
       "0                  Когда появился бессюжетный балет?   \n",
       "1              Кем был захвачен Франческо I Каррара?   \n",
       "2                              Кто такой Лео Фендер?   \n",
       "3                Какой словарь составил Р. Траутман?   \n",
       "4  Какая подвеска применяется на современных трол...   \n",
       "\n",
       "                                        answer char_answer_span  \\\n",
       "0                                    в XX веке       (267, 276)   \n",
       "1                                    миланцами       (510, 519)   \n",
       "2  американский изобретатель и предприниматель         (12, 55)   \n",
       "3                     Балто-славянский словарь       (120, 144)   \n",
       "4        с пневматическими упругими элементами       (200, 237)   \n",
       "\n",
       "                                    paragraph_tokens word_answer_span  \n",
       "0  Бале́т ( фр . ballet , от итал . ballare — тан...            41,44  \n",
       "1  Стоявшие во главе города подеста с конца XII в...            89,90  \n",
       "2  В 1951 году американский изобретатель и предпр...              3,7  \n",
       "3  Исследованиями балтийских языков и их связей с...            17,19  \n",
       "4  Подвеска смягчает и поглощает удары и толчки ,...            28,32  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10067"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2150188c5578446fb5debb9e7e9a9a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=155046), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e014112b1dd34bcd99c4dc85e3eec8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Loading data', max=1, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "par_tokens_train = [i.split() for i in train.paragraph_tokens]\n",
    "que_tokens_train = [tokenize_text(i) for i in train.question]\n",
    "answer_spans_train = train.word_answer_span\n",
    "\n",
    "train_data = QADataset(tokenizer=tokenizer,\n",
    "                   paragraph_tokens=par_tokens_train,\n",
    "                   question_tokens=que_tokens_train,\n",
    "                   answer_spans=answer_spans_train,\n",
    "                   word2index=word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2fcb1dd8ec47f987eadb97d9e252b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=155046), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220fb45779ac48d0b17ef3ac1698e342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Loading data', max=1, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "par_tokens_test = [i.split() for i in test.paragraph_tokens]\n",
    "que_tokens_test = [tokenize_text(i) for i in test.question]\n",
    "answer_spans_test = test.word_answer_span\n",
    "\n",
    "test_data = QADataset(tokenizer=tokenizer,\n",
    "                   paragraph_tokens=par_tokens_test,\n",
    "                   question_tokens=que_tokens_test,\n",
    "                   answer_spans=answer_spans_test,\n",
    "                   word2index=word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. вставить эмбеддинги берта в классификатор\n",
    "# 2. написать бейзлайн\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertForMaskedLM\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "               hidden_size=3072,  \n",
    "               linear_out=3,\n",
    "               batch_first=True):\n",
    "  \n",
    "        super(Classifier, self).__init__()\n",
    "            \n",
    "        self.output_model_file = \"lm/pytorch_model.bin\"\n",
    "        self.output_config_file = \"lm/config.json\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"lm\", do_lower_case=False)\n",
    "        self.config = BertConfig.from_json_file(self.output_config_file)\n",
    "        self.model = BertForMaskedLM(self.config)\n",
    "        device = ('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.state_dict = torch.load(self.output_model_file, map_location=device)\n",
    "        self.model.load_state_dict(self.state_dict)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(hidden_size, linear_out)\n",
    "        \n",
    "    \n",
    "    def get_embeddings(self, x_instance):\n",
    "        indexed_tokens = x_instance.tolist()\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_ids = [1] * len(indexed_tokens)\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = self.model.bert(tokens_tensor,\n",
    "                                       segments_tensors)\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        token_embeddings = token_embeddings.permute(1, 0, 2)\n",
    "        token_vecs_cat = []\n",
    "        for token in token_embeddings:\n",
    "            cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]),\n",
    "                                dim=0)\n",
    "            token_vecs_cat.append(cat_vec)\n",
    "        token_vecs_cat = torch.stack(token_vecs_cat, dim=0)\n",
    "        return token_vecs_cat\n",
    "\n",
    "    \n",
    "    def embed_data(self, x): \n",
    "        entries = [] \n",
    "        data_iterator = tqdm(x, desc='Loading embeddings')    \n",
    "        for entry in data_iterator:\n",
    "            emb = self.get_embeddings(entry)\n",
    "            entries.append(emb)\n",
    "        return torch.stack(entries)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.embed_data(x)\n",
    "        pred = self.linear(h)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=32, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x,y in test_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1214 03:02:37.692151 139737074411328 tokenization.py:187] loading vocabulary file lm/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235dc84a6bb64bada8f2cfab492419a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1214 03:03:49.651472 139737074411328 tokenization.py:187] loading vocabulary file lm/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, drop_last=True)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "device = ('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = Classifier()\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=8e-6, weight_decay=0.01)\n",
    "\n",
    "iteration_losses = []\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "accuracies = []\n",
    "f_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace38d979f3f4e0691f219183f3137f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=40267, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796b780935c8449ea3ef2b0b67dad132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55311cec4218402d8ff49fc9ef56ad49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1339f2b56bf4b489ee04ed1911d7f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b0b5eeaf1b42b6a306962010874c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7149448588e47d5a52db2610b35c721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23e056359f84cc0a95875152f906e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be931232cdf049e5b3600e266008bb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa2301008b041a98e3cf66417a845b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ae7f877a524ef885f3d827b86a480d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "best_test_loss = 1.7 # для early stopping\n",
    "\n",
    "for n_epoch in range(epochs):\n",
    "        \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_targets = []\n",
    "    test_preds = []\n",
    "    \n",
    "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model.forward(x.to(device))  \n",
    "        \n",
    "#        y_vector = [0 for i in range(512)]\n",
    "#        y_vector[int(y[0])] = 1\n",
    "#        y_1 = y_vector\n",
    "        \n",
    "#        y_vector = [0 for i in range(512)]\n",
    "#        y_vector[int(y[1])] = 1\n",
    "#        y_2 = y_vector\n",
    "        \n",
    "        loss = criterion(pred.to(device).permute(0, 2, 1), y.long().to(device))   \n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        iteration_losses.append(loss.item())\n",
    "        train_losses.append(loss.item())\n",
    "        progress_bar.set_postfix(loss=np.mean(iteration_losses[-500:]))\n",
    "        progress_bar.update(x.shape[0])\n",
    "        \n",
    "    progress_bar.close()\n",
    "    epoch_train_losses.append(np.mean(train_losses))\n",
    "  \n",
    " #    for x_test, y_test in test_loader:\n",
    " #        with torch.no_grad():\n",
    " #           pred = model.forward(x_test.to(device))\n",
    " #           test_preds.append(pred.cpu()) \n",
    " #       test_targets.append(y_test.long())\n",
    " #       loss = criterion(pred, y_test.long().to(device))\n",
    " #       test_losses.append(loss.item()) \n",
    "        \n",
    " #       mean_test_loss = np.mean(test_losses)\n",
    " #   epoch_test_losses.append(mean_test_loss)\n",
    "    \n",
    " #   print('Training: train loss = {:.3f}, test loss = {:.3f} '.format(np.mean(train_losses), mean_test_loss))\n",
    " #   print(\"Evaluating...\")\n",
    "    \n",
    " #   test_preds_cat = torch.cat(test_preds, dim=0)\n",
    " #   test_preds_argmax = torch.argmax(test_preds_cat, dim=1)\n",
    " #   test_targets = torch.cat(test_targets, dim=0)  \n",
    "\n",
    " #   accuracy = accuracy_score(test_targets, test_preds_argmax)\n",
    " #   f_score = f1_score(test_targets, test_preds_argmax, average='macro')\n",
    " #   accuracies.append(accuracy)\n",
    " #   f_scores.append(f_score)\n",
    " #   print('Accuracy = {:.3f}, f1-score = {:.3f}'.format(accuracy, f_score))\n",
    "    \n",
    " #   if mean_test_loss < best_test_loss:\n",
    " #       best_test_loss = mean_test_loss\n",
    " #   else:\n",
    " #       print('Early stopping')\n",
    " #       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3533711b92974c25876d0bc43ea0707e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading embeddings', max=32, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "h = model.embed_data(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 3072])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0038, device='cuda:0', grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(pred.to(device).permute(0, 2, 1), y.long().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
