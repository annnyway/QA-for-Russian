{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !gdown https://drive.google.com/uc?id=11AENyWl6fD5rgoIIwnZy692vE_pqZQ8Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown https://drive.google.com/uc?id=1ZCgMnlPTQvmU4KB5HQpLGFNZt-uEzNks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip zipfile.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm zipfile.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas razdel tqdm python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from main import QADataset\n",
    "from razdel import tokenize\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from preprocess_dataset import tokenize_text\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertModel, BertTokenizer, BertForMaskedLM, BertConfig\n",
    "from get_bert_embeddings import get_embeddings, embed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>char_answer_span</th>\n",
       "      <th>paragraph_tokens</th>\n",
       "      <th>word_answer_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14754</td>\n",
       "      <td>60544</td>\n",
       "      <td>Первые упоминания о строении человеческого тел...</td>\n",
       "      <td>Где встречаются первые упоминания о строении ч...</td>\n",
       "      <td>в Древнем Египте</td>\n",
       "      <td>(60, 76)</td>\n",
       "      <td>Первые упоминания о строении человеческого тел...</td>\n",
       "      <td>7,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13859</td>\n",
       "      <td>1604</td>\n",
       "      <td>Телескоп имеет модульную структуру и содержит ...</td>\n",
       "      <td>Как называется корректирующая оптическая систе...</td>\n",
       "      <td>COSTAR</td>\n",
       "      <td>(187, 193)</td>\n",
       "      <td>Телескоп имеет модульную структуру и содержит ...</td>\n",
       "      <td>28,29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8310</td>\n",
       "      <td>30350</td>\n",
       "      <td>Критики теории Вегенера поставили во главу угл...</td>\n",
       "      <td>Какая теория была отвергнута после смерти Веге...</td>\n",
       "      <td>теория дрейфа материков</td>\n",
       "      <td>(335, 358)</td>\n",
       "      <td>Критики теории Вегенера поставили во главу угл...</td>\n",
       "      <td>51,54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8766</td>\n",
       "      <td>53270</td>\n",
       "      <td>При нагревании кусочки янтаря становятся очень...</td>\n",
       "      <td>Чему не уступают по красоте изделия из прессов...</td>\n",
       "      <td>изделиям из монолитных камней</td>\n",
       "      <td>(852, 881)</td>\n",
       "      <td>При нагревании кусочки янтаря становятся очень...</td>\n",
       "      <td>128,132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14719</td>\n",
       "      <td>75698</td>\n",
       "      <td>Нисходящие дифтонги со слабым гласным /i/ и /u...</td>\n",
       "      <td>На какие группы классифицируют дифтонги?</td>\n",
       "      <td>оральные и назальные</td>\n",
       "      <td>(735, 755)</td>\n",
       "      <td>Нисходящие дифтонги со слабым гласным / i / и ...</td>\n",
       "      <td>141,144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0         14754        60544   \n",
       "1         13859         1604   \n",
       "2          8310        30350   \n",
       "3          8766        53270   \n",
       "4         14719        75698   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Первые упоминания о строении человеческого тел...   \n",
       "1  Телескоп имеет модульную структуру и содержит ...   \n",
       "2  Критики теории Вегенера поставили во главу угл...   \n",
       "3  При нагревании кусочки янтаря становятся очень...   \n",
       "4  Нисходящие дифтонги со слабым гласным /i/ и /u...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Где встречаются первые упоминания о строении ч...   \n",
       "1  Как называется корректирующая оптическая систе...   \n",
       "2  Какая теория была отвергнута после смерти Веге...   \n",
       "3  Чему не уступают по красоте изделия из прессов...   \n",
       "4           На какие группы классифицируют дифтонги?   \n",
       "\n",
       "                          answer char_answer_span  \\\n",
       "0               в Древнем Египте         (60, 76)   \n",
       "1                         COSTAR       (187, 193)   \n",
       "2        теория дрейфа материков       (335, 358)   \n",
       "3  изделиям из монолитных камней       (852, 881)   \n",
       "4           оральные и назальные       (735, 755)   \n",
       "\n",
       "                                    paragraph_tokens word_answer_span  \n",
       "0  Первые упоминания о строении человеческого тел...             7,10  \n",
       "1  Телескоп имеет модульную структуру и содержит ...            28,29  \n",
       "2  Критики теории Вегенера поставили во главу угл...            51,54  \n",
       "3  При нагревании кусочки янтаря становятся очень...          128,132  \n",
       "4  Нисходящие дифтонги со слабым гласным / i / и ...          141,144  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sdsj2017_sberquad_with_spans(minus_30_examples).csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_tokens = [i.split() for i in data.paragraph_tokens]\n",
    "que_tokens = [tokenize_text(i) for i in data.question]\n",
    "answer_spans = data.word_answer_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index={\"[PAD]\":0, \"[CLS]\":1, \"[SEP]\":2}\n",
    "\n",
    "for sent in par_tokens:\n",
    "    for token in sent:\n",
    "        if token not in word2index:\n",
    "            word2index[token] = len(word2index)\n",
    "\n",
    "for que in que_tokens:\n",
    "    for token in que:\n",
    "        if token not in word2index:\n",
    "            word2index[token] = len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"lm\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are good to go!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('Bummer!  Training on CPU ...')\n",
    "else:\n",
    "    print('You are good to go!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = embed_data(dataset.x_data)\n",
    "# тут все ок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем датасет на трейн/тест (80%, 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40267"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>char_answer_span</th>\n",
       "      <th>paragraph_tokens</th>\n",
       "      <th>word_answer_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11398</td>\n",
       "      <td>27507</td>\n",
       "      <td>Идея о том, что человечество развивается по пу...</td>\n",
       "      <td>Кто первым изложил последовательную теорию про...</td>\n",
       "      <td>аббат Сен-Пьер</td>\n",
       "      <td>(288, 302)</td>\n",
       "      <td>Идея о том , что человечество развивается по п...</td>\n",
       "      <td>48,50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8918</td>\n",
       "      <td>59781</td>\n",
       "      <td>Когда на трон развивающейся страны взошёл царь...</td>\n",
       "      <td>В какой период Болгарское царство достигло апо...</td>\n",
       "      <td>период правления Симеона</td>\n",
       "      <td>(136, 160)</td>\n",
       "      <td>Когда на трон развивающейся страны взошёл царь...</td>\n",
       "      <td>23,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4245</td>\n",
       "      <td>14011</td>\n",
       "      <td>Углеводы — весьма обширный класс органических ...</td>\n",
       "      <td>какие главные источники углеводов в пище являю...</td>\n",
       "      <td>хлеб, картофель, макароны, крупы, сладости</td>\n",
       "      <td>(732, 774)</td>\n",
       "      <td>Углеводы — весьма обширный класс органических ...</td>\n",
       "      <td>109,118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8258</td>\n",
       "      <td>3495</td>\n",
       "      <td>Речно́й о́кунь[1], или обыкнове́нный окунь[2] ...</td>\n",
       "      <td>Какой вид окуней есть в водоёмах Северной Амер...</td>\n",
       "      <td>жёлтый окунь (Perca flavescens)</td>\n",
       "      <td>(524, 555)</td>\n",
       "      <td>Речно́й о́кунь [ 1 ] , или обыкнове́нный окунь...</td>\n",
       "      <td>91,97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7381</td>\n",
       "      <td>32304</td>\n",
       "      <td>Подавляющее большинство правивших в Северной А...</td>\n",
       "      <td>Последователи Абдуллы ибн Ясина стали основате...</td>\n",
       "      <td>Альморавидов</td>\n",
       "      <td>(120, 132)</td>\n",
       "      <td>Подавляющее большинство правивших в Северной А...</td>\n",
       "      <td>15,16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0         11398        27507   \n",
       "1          8918        59781   \n",
       "2          4245        14011   \n",
       "3          8258         3495   \n",
       "4          7381        32304   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Идея о том, что человечество развивается по пу...   \n",
       "1  Когда на трон развивающейся страны взошёл царь...   \n",
       "2  Углеводы — весьма обширный класс органических ...   \n",
       "3  Речно́й о́кунь[1], или обыкнове́нный окунь[2] ...   \n",
       "4  Подавляющее большинство правивших в Северной А...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Кто первым изложил последовательную теорию про...   \n",
       "1  В какой период Болгарское царство достигло апо...   \n",
       "2  какие главные источники углеводов в пище являю...   \n",
       "3  Какой вид окуней есть в водоёмах Северной Амер...   \n",
       "4  Последователи Абдуллы ибн Ясина стали основате...   \n",
       "\n",
       "                                       answer char_answer_span  \\\n",
       "0                              аббат Сен-Пьер       (288, 302)   \n",
       "1                    период правления Симеона       (136, 160)   \n",
       "2  хлеб, картофель, макароны, крупы, сладости       (732, 774)   \n",
       "3             жёлтый окунь (Perca flavescens)       (524, 555)   \n",
       "4                                Альморавидов       (120, 132)   \n",
       "\n",
       "                                    paragraph_tokens word_answer_span  \n",
       "0  Идея о том , что человечество развивается по п...            48,50  \n",
       "1  Когда на трон развивающейся страны взошёл царь...            23,26  \n",
       "2  Углеводы — весьма обширный класс органических ...          109,118  \n",
       "3  Речно́й о́кунь [ 1 ] , или обыкнове́нный окунь...            91,97  \n",
       "4  Подавляющее большинство правивших в Северной А...            15,16  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10067"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb8197c97f94bb4b136468ce8c3fbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=155046.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50cfb4f4a2f4bfeb1639e77985bf9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Loading data', max=1.0, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "par_tokens_train = [i.split() for i in train.paragraph_tokens]\n",
    "que_tokens_train = [tokenize_text(i) for i in train.question]\n",
    "answer_spans_train = train.word_answer_span\n",
    "\n",
    "train_data = QADataset(tokenizer=tokenizer,\n",
    "                   paragraph_tokens=par_tokens_train,\n",
    "                   question_tokens=que_tokens_train,\n",
    "                   answer_spans=answer_spans_train,\n",
    "                   word2index=word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be862222d724d67bc5367ad07028cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=155046.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f5f896f1fd48078cd485cafb087856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Loading data', max=1.0, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "par_tokens_test = [i.split() for i in test.paragraph_tokens]\n",
    "que_tokens_test = [tokenize_text(i) for i in test.question]\n",
    "answer_spans_test = test.word_answer_span\n",
    "\n",
    "test_data = QADataset(tokenizer=tokenizer,\n",
    "                   paragraph_tokens=par_tokens_test,\n",
    "                   question_tokens=que_tokens_test,\n",
    "                   answer_spans=answer_spans_test,\n",
    "                   word2index=word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. вставить эмбеддинги берта в классификатор\n",
    "# 2. написать бейзлайн\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertForMaskedLM\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "               hidden_size=3072,  \n",
    "               linear_out=512,\n",
    "               batch_first=True):\n",
    "  \n",
    "        super(Classifier, self).__init__()\n",
    "            \n",
    "        self.output_model_file = \"lm/pytorch_model.bin\"\n",
    "        self.output_config_file = \"lm/config.json\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"lm\", do_lower_case=False)\n",
    "        self.config = BertConfig.from_json_file(self.output_config_file)\n",
    "        self.model = BertForMaskedLM(self.config)\n",
    "        self.state_dict = torch.load(self.output_model_file, map_location=device)\n",
    "        self.model.load_state_dict(self.state_dict)\n",
    "        \n",
    "        self.linear_1 = torch.nn.Linear(hidden_size, linear_out)\n",
    "        self.linear_2 = torch.nn.Linear(hidden_size, linear_out)\n",
    "        \n",
    "    \n",
    "    def get_embeddings(self, x_instance):\n",
    "        indexed_tokens = x_instance.tolist()\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_ids = [1] * len(indexed_tokens)\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = self.model.bert(tokens_tensor,\n",
    "                                       segments_tensors)\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        token_embeddings = token_embeddings.permute(1, 0, 2)\n",
    "        token_vecs_cat = []\n",
    "        for token in token_embeddings:\n",
    "            cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]),\n",
    "                                dim=0)\n",
    "            token_vecs_cat.append(cat_vec)\n",
    "        token_vecs_cat = torch.stack(token_vecs_cat, dim=0)\n",
    "        sentence_embedding = torch.mean(token_vecs_cat, dim=0)\n",
    "\n",
    "        return sentence_embedding\n",
    "\n",
    "    \n",
    "    def embed_data(self, x): \n",
    "        entries = [] \n",
    "        data_iterator = tqdm(x, desc='Loading embeddings')    \n",
    "        for entry in data_iterator:\n",
    "            emb = self.get_embeddings(entry)\n",
    "            entries.append(emb)\n",
    "        return torch.stack(entries)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.embed_data(x)\n",
    "        pred_1 = self.linear_1(h)\n",
    "        pred_2 = self.linear_2(h)\n",
    "        \n",
    "        return pred_1, pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=32, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x,y in test_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d883d32e97a41d6a31e8791efe5fa66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading embeddings', max=32.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_1, pred_2 = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, drop_last=True)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "device = ('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = Classifier()\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=8e-6, weight_decay=0.01)\n",
    "\n",
    "iteration_losses = []\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "accuracies = []\n",
    "f_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1719a185b54bbeadc0545704f94d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=40267.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e073ee7f4cef47e996f491eee5f01eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading embeddings', max=32.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-51988b713cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#        y_2 = y_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "best_test_loss = 1.7 # для early stopping\n",
    "\n",
    "for n_epoch in range(epochs):\n",
    "        \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_targets = []\n",
    "    test_preds = []\n",
    "    \n",
    "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_1, pred_2 = model.forward(x.to(device))  \n",
    "        \n",
    "#        y_vector = [0 for i in range(512)]\n",
    "#        y_vector[int(y[0])] = 1\n",
    "#        y_1 = y_vector\n",
    "        \n",
    "#        y_vector = [0 for i in range(512)]\n",
    "#        y_vector[int(y[1])] = 1\n",
    "#        y_2 = y_vector\n",
    "        \n",
    "        loss_1 = criterion(pred_1, y_1.long().to(device))  \n",
    "        loss_2 = criterion(pred_2, y_2.long().to(device))  \n",
    "        loss = loss_1 + loss_2\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        iteration_losses.append(loss.item())\n",
    "        train_losses.append(loss.item())\n",
    "        progress_bar.set_postfix(loss=np.mean(iteration_losses[-500:]))\n",
    "        progress_bar.update(x.shape[0])\n",
    "        \n",
    "    progress_bar.close()\n",
    "    epoch_train_losses.append(np.mean(train_losses))\n",
    "  \n",
    " #    for x_test, y_test in test_loader:\n",
    " #        with torch.no_grad():\n",
    " #           pred = model.forward(x_test.to(device))\n",
    " #           test_preds.append(pred.cpu()) \n",
    " #       test_targets.append(y_test.long())\n",
    " #       loss = criterion(pred, y_test.long().to(device))\n",
    " #       test_losses.append(loss.item()) \n",
    "        \n",
    " #       mean_test_loss = np.mean(test_losses)\n",
    " #   epoch_test_losses.append(mean_test_loss)\n",
    "    \n",
    " #   print('Training: train loss = {:.3f}, test loss = {:.3f} '.format(np.mean(train_losses), mean_test_loss))\n",
    " #   print(\"Evaluating...\")\n",
    "    \n",
    " #   test_preds_cat = torch.cat(test_preds, dim=0)\n",
    " #   test_preds_argmax = torch.argmax(test_preds_cat, dim=1)\n",
    " #   test_targets = torch.cat(test_targets, dim=0)  \n",
    "\n",
    " #   accuracy = accuracy_score(test_targets, test_preds_argmax)\n",
    " #   f_score = f1_score(test_targets, test_preds_argmax, average='macro')\n",
    " #   accuracies.append(accuracy)\n",
    " #   f_scores.append(f_score)\n",
    " #   print('Accuracy = {:.3f}, f1-score = {:.3f}'.format(accuracy, f_score))\n",
    "    \n",
    " #   if mean_test_loss < best_test_loss:\n",
    " #       best_test_loss = mean_test_loss\n",
    " #   else:\n",
    " #       print('Early stopping')\n",
    " #       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
